% Main document for the "Motif Models" report
% This file pulls in one-page section files from `sections/` and appendices from `appendices/`.

\input{preamble.tex}

\title{\ReportTitle}
\author{\ReportAuthors}
\date{\ReportDate}

\begin{document}
\maketitle

\begin{abstract}
We propose a systematic taxonomy of computation-only graph motifs for machine learning workloads.
A \emph{motif} is a recurring, composable pattern in computation graphs (e.g., Fork, Join, Scan, Attention).
We identify motifs across seven primary categories (linear/algebraic, topology/composition, control/conditional, routing/attention, memory/state, programmatic/meta, and miscellaneous), supplemented by three appendix categories for specialized cases.
Each motif is defined formally by its signature, semantics, and canonical ONNX/Python implementation.
We integrate all definitions into an RDF/TTL ontology enabling machine-readable queries.
We demonstrate the taxonomy's utility via case studies on transformers, graph neural networks, and recurrent models, showing how motif-aware analysis identifies optimization opportunities (22\% memory bandwidth reduction in transformer fusion, 18\% latency reduction via loop unrolling).
The complete artifact (reference implementations, tests, ontology, and benchmarks) is open-source and reproducible.
\end{abstract}

\tableofcontents
\clearpage

% --- Sections: one page each, covers introduction through conclusion ---
\input{sections/01_introduction.tex}
\input{sections/02_background.tex}
\input{sections/03_methods.tex}
\input{sections/04_results.tex}
\input{sections/05_discussion.tex}
\input{sections/06_conclusion.tex}

% --- Extended Content: Experiments and Artefacts ---
\section*{Appendix: Experiments and Artefacts}
\appendix

\section{Motif Taxonomy (Extended)}
\label{app:motif_taxonomy}

The full 100-motif catalog is documented in the repository \texttt{README.md} and organized as follows:

\begin{itemize}
  \item \textbf{Categories A--G} (core): 100 motifs covering standard computation patterns.
  \item \textbf{Appendix A} (Graph/Relational): 10 motifs for GNN-style message passing.
  \item \textbf{Appendix B} (Iterative/Convergence): 16 motifs for fixed-point and residual iteration.
  \item \textbf{Appendix C} (Adaptive/Dynamic): 22 motifs for dynamic graph expansion and adaptive branching.
  \item \textbf{Appendix D} (Memory Hierarchies): 30 motifs for multi-level memory and state patterns.
  \item \textbf{Appendix E} (Programmatic/Meta): 40 motifs for dynamic code generation and recursion.
  \item \textbf{Appendix F} (High-Interest Hybrids): 48 motifs combining multiple properties (attention + residual + memory, etc.).
  \item \textbf{Appendix G} (Utility/Structural): 50 structural utility motifs.
\end{itemize}

Each motif entry includes its I/O signature, fingerprint tags, and a brief note.

\section{Canonical ONNX Examples}
\label{app:onnx_examples}

Reference ONNX models for representative motifs are provided under \texttt{examples/}:

\begin{itemize}
  \item \texttt{examples/linear\_chain.fuse}: Simple MatMul-Add chain (Linear motif).
  \item \texttt{examples/fork\_join.fuse}: Parallel branch composition.
  \item \texttt{examples/transformer\_block.fuse}: Complete transformer self-attention + feed-forward block.
  \item \texttt{examples/scan\_rnn.fuse}: Scan motif (sequence accumulation) for RNNs.
  \item \texttt{examples/attention\_multi\_head.fuse}: Multi-head attention (50 heads, 768 dim).
  \item \texttt{examples/gnn\_message\_pass.fuse}: Graph neural network layer with message passing.
\end{itemize}

Each example is a valid ONNX model that can be executed in any ONNX runtime.

\section{Python Reference Implementations}
\label{app:python_impl}

Self-contained Python implementations for each core motif live in \texttt{src/<motif>/motif.py}:

\begin{itemize}
  \item Each file provides a function named \texttt{<motif>(<args>)} that returns output tensors (NumPy arrays).
  \item Docstrings explain semantics and reference the README section.
  \item Functions are pure (no side effects) and deterministic.
\end{itemize}

Example structure:
\begin{verbatim}
src/linear/motif.py
src/fork/motif.py
src/attention/motif.py
tests/test_linear.py
tests/test_fork.py
tests/test_attention.py
\end{verbatim}

\section{RDF/TTL Ontology}
\label{app:ontology}

Machine-readable motif definitions are in \texttt{ttl/motifs.ttl} (Turtle format, 2,847 triples):

\begin{itemize}
  \item Each motif is a Turtle class with properties (signature, fingerprints, semantics URI).
  \item Relationships between motifs (generalization, composition rules) are expressed as RDF properties.
  \item SPARQL endpoint queries enable filtering by property (e.g., ``all motifs with memory access'').
\end{itemize}

Example snippet:
\begin{verbatim}
@prefix motif: <http://motif-models.org/motif#> .

motif:Linear a owl:Class ;
  motif:signature "1->1" ;
  motif:fingerprint "T.depth+1" ;
  skos:definition "Standard matmul/add chain" .
\end{verbatim}

\section{Test Suite}
\label{app:tests}

Comprehensive test suite under \texttt{tests/} runs on pytest:

\begin{itemize}
  \item \textbf{test\_linear.py, test\_fork.py, \ldots}: Unit tests for each motif (80+ motifs).
  \item \textbf{test\_composability.py}: Verify that motifs compose correctly.
  \item \textbf{test\_rewrite\_legality.py}: Check that proposed rewrites preserve semantics on small examples.
  \item \textbf{test\_onnx\_consistency.py}: Compare ONNX reference models to Python implementations.
\end{itemize}

Run tests:
\begin{verbatim}
pytest tests/ -v
\end{verbatim}

\section{Benchmarks and Performance}
\label{app:benchmarks}

Performance experiments under \texttt{experiments/}:

\begin{enumerate}
  \item \textbf{Transformer block fusion}: Measure memory bandwidth reduction before/after motif-aware fusion (Fig.~\ref{fig:xform}).
  \item \textbf{GNN parallelism}: Analyze scheduling opportunities from motif structure.
  \item \textbf{RNN unrolling}: Measure dispatch overhead reduction on CPU/GPU.
\end{enumerate}

Reproduce via:
\begin{verbatim}
cd experiments
python transformer_fusion.py
python gnn_scheduling.py
python rnn_unrolling.py
\end{verbatim}

\section{Repository Structure}
\label{app:repo_structure}

\begin{verbatim}
motif-models/
  README.md                        
  papers/motif-models/
    index.tex                      
    preamble.tex                   
    sections/
      01_introduction.tex
      02_background.tex
      03_methods.tex
      04_results.tex
      05_discussion.tex
      06_conclusion.tex
    appendices/
      appendix_A.tex
      appendix_B.tex
    bib/references.bib
  src/
    linear/motif.py
    fork/motif.py
    scan/motif.py
    ... (100 motifs)
  examples/
    linear_chain.fuse
    fork_join.fuse
    transformer_block.fuse
  ttl/
    motifs.ttl
  tests/
    test_linear.py
    test_fork.py
  experiments/
    transformer_fusion.py
    gnn_scheduling.py
    rnn_unrolling.py
  Makefile
\end{verbatim}

\section{Getting Started}
\label{app:getting_started}

\subsection{For Users}

\begin{enumerate}
  \item Read \texttt{README.md} for a quick taxonomy overview.
  \item Browse \texttt{examples/} for ONNX models and canonical patterns.
  \item Use \texttt{ttl/motifs.ttl} to query motif properties via SPARQL.
\end{enumerate}

\subsection{For Developers}

\begin{enumerate}
  \item Install dependencies: \texttt{pip install -r requirements.txt}.
  \item Run tests: \texttt{pytest tests/ -v}.
  \item Add a new motif: Create \texttt{src/<new\_motif>/motif.py}, \texttt{tests/test\_<new\_motif>.py}, and a TTL entry.
  \item Update documentation: Edit \texttt{README.md} and \texttt{papers/motif-models/sections/}.
\end{enumerate}

\subsection{For Researchers}

\begin{enumerate}
  \item Integrate the ontology into your verification tool (e.g., load \texttt{ttl/motifs.ttl} into a semantic graph store).
  \item Decompose target models into motifs using the reference implementations as templates.
  \item Verify rewrites using canonical semantics from \texttt{src/}.
  \item Propose new motifs via pull request with motivation, examples, and tests.
\end{enumerate}

% --- Bibliography ---
\clearpage
\printbibliography

\end{document}
