@fuse 1.2
@opset onnx 18
@domain examples.golden.jepa
@attribution "Inspired by I-JEPA (LeCun et al., Meta AI, 2023)"

@id  "https://ns.onnx.cloud/examples.golden.jepa"
@doc "Golden-reference JEPA: patch encoder, predictor, target encoder, and training graphs."

# 
# Type System
# 

# Batch-generic image and latent types
type Img224     = f32[B,3,224,224]
type PatchTok   = f32[B,196,768]
type PatchMask  = bool[B,196]
type Scalar     = f32

# 
# Parameters
# 

# Trainable encoder + predictor
@train  weight W_patch : f32[768,3,16,16]
@train  weight b_patch : f32[768]

@train  weight W_p1    : f32[768,768]
@train  weight b_p1    : f32[768]
@train  weight W_p2    : f32[768,768]
@train  weight b_p2    : f32[768]

# Frozen target encoder
@frozen weight W_t_patch : f32[768,3,16,16]
@frozen weight b_t_patch : f32[768]

# 
# Patch Encoder
# 

@doc  "Conv-based patchification producing latent tokens."
@type "https://ns.onnx.cloud/examples.golden.jepa.patch.encode"
node patch_encode(
  x : Img224,
  W : f32[768,3,16,16],
  b : f32[768]
) -> PatchTok {

  # 16×16 non-overlapping patches
  p = Conv(
        x, W, b,
        stride@=16,
        pads@=[0,0,0,0]
      )

  # (B,768,14,14) → (B,196,768)
  z = Reshape(p, [B,196,768])
  return z
}

# 
# Predictor
# 

@doc  "Latent-space predictor mapping context tokens to targets."
@type "https://ns.onnx.cloud/examples.golden.jepa.predictor"
node predictor(
  z_ctx : PatchTok
) -> PatchTok {

  h1  = z_ctx @ W_p1
  h1b = h1 + b_p1
  h1a = Relu(h1b)

  h2  = h1a @ W_p2
  out = h2 + b_p2
  return out
}

# 
# Mask Utilities
# 

@doc "Applies a boolean patch mask to latent tensors."
node apply_mask(
  z    : PatchTok,
  mask : PatchMask
) -> PatchTok {

  m  = Cast(mask, to@="f32")
  m3 = Unsqueeze(m, axes@=[2])
  return z * m3
}

# 
# Loss
# 

@doc  "Masked latent regression energy (MSE)."
@type "https://ns.onnx.cloud/examples.golden.jepa.latent.energy"
node latent_mse(
  z_hat : PatchTok,
  z_tgt : PatchTok,
  mask  : PatchMask
) -> Scalar {

  diff   = z_hat - z_tgt
  sq     = diff * diff
  masked = apply_mask(sq, mask)

  num   = ReduceSum(masked)
  denom = ReduceSum(Cast(mask, to@="f32"))

  return num / denom
}

# 
# Training Graph
# 

@doc  "End-to-end JEPA training graph."
@id   "https://my.onnx.cloud/examples.golden.jepa.training"
@type "https://ns.onnx.cloud/examples.golden.jepa.training"

@training {
  optimizer = Adam,
  lr        = 1e-3
}

graph jepa_train(
  x_ctx : Img224,
  x_tgt : Img224,
  mask  : PatchMask
) -> (
  z_pred : PatchTok,
  z_tgt  : PatchTok,
  loss   : Scalar
) {

  # Context → prediction
  z_ctx  = patch_encode(x_ctx, W_patch, b_patch)
  z_pred = predictor(z_ctx)

  # Target (frozen)
  z_tgt  = patch_encode(x_tgt, W_t_patch, b_t_patch)

  loss = latent_mse(z_pred, z_tgt, mask)
  return z_pred, z_tgt, loss
}

# 
# Slice Graphs
# 

@doc  "Encoder-only inference graph."
@id   "https://my.onnx.cloud/examples.golden.jepa.encode"
@type "https://ns.onnx.cloud/examples.golden.jepa.encode"
graph jepa_encode(
  x : Img224
) -> PatchTok {

  return patch_encode(x, W_patch, b_patch)
}

@doc  "Predictor-only inference graph."
@id   "https://my.onnx.cloud/examples.golden.jepa.predict"
@type "https://ns.onnx.cloud/examples.golden.jepa.predict"
graph jepa_predict(
  z_ctx : PatchTok
) -> PatchTok {

  return predictor(z_ctx)
}

@doc  "Frozen target encoder graph."
@id   "https://my.onnx.cloud/examples.golden.jepa.target.encode"
@type "https://ns.onnx.cloud/examples.golden.jepa.target.encode"
graph jepa_target_encode(
  x : Img224
) -> PatchTok {

  return patch_encode(x, W_t_patch, b_t_patch)
}
